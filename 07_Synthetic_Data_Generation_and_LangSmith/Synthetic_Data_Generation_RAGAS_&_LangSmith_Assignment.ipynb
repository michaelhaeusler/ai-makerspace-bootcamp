{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCk2Rx4cjlYF"
      },
      "source": [
        "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
        "\n",
        "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
        "\n",
        "\n",
        "\n",
        "- 🤝 BREAKOUT ROOM #1\n",
        "  1. Use RAGAS to Generate Synthetic Data\n",
        "\n",
        "- 🤝 BREAKOUT ROOM #2\n",
        "  1. Load them into a LangSmith Dataset\n",
        "  2. Evaluate our RAG chain against the synthetic test data\n",
        "  3. Make changes to our pipeline\n",
        "  4. Evaluate the modified pipeline\n",
        "\n",
        "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bG2ta-B478G"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUI7vF_kbv9"
      },
      "source": [
        "## Task 1: Dependencies and API Keys\n",
        "\n",
        "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
        "\n",
        "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
        "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
        "3. QDrant as our vectorstore\n",
        "4. LangSmith for our evaluation coordinator!\n",
        "\n",
        "Let's install and provide all the required information below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies and API Keys:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NLTK Import\n",
        "\n",
        "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/Micha/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/Micha/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll also want to set a project name to make things easier for ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI's API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - which should hopefull be familiar at this point since it's our Use-Case Data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unrolled SDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to instantiate our Knowledge Graph.\n",
        "\n",
        "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 0, relationships: 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 64, relationships: 0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
        "for doc in docs:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
        "\n",
        "These default transformations are dependent on the corpus length, in our case:\n",
        "\n",
        "- Producing Summaries -> produces summaries of the documents\n",
        "- Extracting Headlines -> finding the overall headline for the document\n",
        "- Theme Extractor -> extracts broad themes about the documents\n",
        "\n",
        "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a9f89f393c34b72830ab3d99c5df58f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78635af8320c4b79abc5affeca43d67a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1aa76839ea447ba831f51b5ecc2f3c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '907b38'. Skipping!\n",
            "Property 'summary' already exists in node '373c6c'. Skipping!\n",
            "Property 'summary' already exists in node '4070b3'. Skipping!\n",
            "Property 'summary' already exists in node '6e9259'. Skipping!\n",
            "Property 'summary' already exists in node '8a50a5'. Skipping!\n",
            "Property 'summary' already exists in node '1b2056'. Skipping!\n",
            "Property 'summary' already exists in node 'c689b1'. Skipping!\n",
            "Property 'summary' already exists in node '40ee84'. Skipping!\n",
            "Property 'summary' already exists in node '6d3e55'. Skipping!\n",
            "Property 'summary' already exists in node '1b3053'. Skipping!\n",
            "Property 'summary' already exists in node '83e288'. Skipping!\n",
            "Property 'summary' already exists in node 'c17daa'. Skipping!\n",
            "Property 'summary' already exists in node 'c2498b'. Skipping!\n",
            "Property 'summary' already exists in node '01863a'. Skipping!\n",
            "Property 'summary' already exists in node '6554ad'. Skipping!\n",
            "Property 'summary' already exists in node '1af5a3'. Skipping!\n",
            "Property 'summary' already exists in node 'e14262'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fe75c2f020645cd81abe38e20622078",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71ed2778dc374f6d9f119feab2adca85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '6e9259'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '8a50a5'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '373c6c'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '1b2056'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c17daa'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '907b38'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '83e288'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '4070b3'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '6d3e55'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '40ee84'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c689b1'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '1b3053'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c2498b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '01863a'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '6554ad'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '1af5a3'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e14262'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "168218fb4053406a98bc49fee0aea098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 711)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import default_transforms, apply_transforms\n",
        "\n",
        "transformer_llm = generator_llm\n",
        "embedding_model = generator_embeddings\n",
        "\n",
        "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
        "apply_transforms(kg, default_transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save and load our knowledge graphs as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 86, relationships: 711)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"usecase_data_kg.json\")\n",
        "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
        "usecase_data_kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=usecase_data_kg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
        "\n",
        "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
        "\n",
        "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "\n",
        "query_distribution = [\n",
        "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
        "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
        "\n",
        "#### ✅ Answer #1:\n",
        "\n",
        "**SingleHopSpecificQuerySynthesizer**\n",
        "Generates simple questions that can be answered with a single piece of information from one source (simple facts).\n",
        "*Example:* What is the capital of Paris 😉\n",
        "\n",
        "**MultiHopAbstractQuerySynthesizer**\n",
        "Generates abstract questions that need complex reasoning (connecting concepts)\n",
        "*Example* How do neural networks relate to artificial intelligence?\n",
        "\n",
        "**MultiHopSpecificQuerySynthesizer**\n",
        "Generates questions that need multiple specific facts to answer (complex facts)\n",
        "*Example* What are the advantages of deep learning over traditional machine learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use our `TestSetGenerator` to generate our testset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "817b584e54114fe39beb63cf1a0d9f65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "583c7ae5949346a7bf41985369a582e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9339ca24065042b4956dae1f4fdeffc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What does Acemoglu, 2024 say about AI's impact?</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>The text mentions that Acemoglu, 2024, is one ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the AI model Claude compare to ChatGP...</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>According to the provided context, ChatGPT's d...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Computer related occupations use ChatGPT?</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>Variation by Occupation Figure 23 shows that 5...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What role does personal reflection play in und...</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>The provided context does not mention personal...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the prvacy-preserving methdology in C...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The paper introduces a novel privacy-preservin...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how much of chatgpt messages are non work and ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>In June 2024, non-work messages accounted for ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Based on the data showing that the most common...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context indicates that Writing is the most...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Considering the rapid growth of ChatGPT usage ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>The context indicates that in the US, over 70%...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Wha US is the US that ChatGPT use in, and how ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>The context indicates that the US refers to th...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does the rapid growth of ChatGPT to over 7...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>By July 2025, ChatGPT had been used weekly by ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does the growth of ChatGPT usage by July 2...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>By July 2025, ChatGPT had experienced rapid gr...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0     What does Acemoglu, 2024 say about AI's impact?   \n",
              "1   How does the AI model Claude compare to ChatGP...   \n",
              "2           Computer related occupations use ChatGPT?   \n",
              "3   What role does personal reflection play in und...   \n",
              "4   How does the prvacy-preserving methdology in C...   \n",
              "5   how much of chatgpt messages are non work and ...   \n",
              "6   Based on the data showing that the most common...   \n",
              "7   Considering the rapid growth of ChatGPT usage ...   \n",
              "8   Wha US is the US that ChatGPT use in, and how ...   \n",
              "9   How does the rapid growth of ChatGPT to over 7...   \n",
              "10  How does the growth of ChatGPT usage by July 2...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Introduction ChatGPT launched in November 202...   \n",
              "1   [Table 1: ChatGPT daily message counts (millio...   \n",
              "2   [Variation by Occupation Figure 23 presents va...   \n",
              "3   [Conclusion This paper studies the rapid growt...   \n",
              "4   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "5   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "6   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "7   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "8   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "9   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "10  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The text mentions that Acemoglu, 2024, is one ...   \n",
              "1   According to the provided context, ChatGPT's d...   \n",
              "2   Variation by Occupation Figure 23 shows that 5...   \n",
              "3   The provided context does not mention personal...   \n",
              "4   The paper introduces a novel privacy-preservin...   \n",
              "5   In June 2024, non-work messages accounted for ...   \n",
              "6   The context indicates that Writing is the most...   \n",
              "7   The context indicates that in the US, over 70%...   \n",
              "8   The context indicates that the US refers to th...   \n",
              "9   By July 2025, ChatGPT had been used weekly by ...   \n",
              "10  By July 2025, ChatGPT had experienced rapid gr...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_specific_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4d0302bfe2b4b48883558d5ef3e5d28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec4391ad8220454e9475518870c3ff8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/64 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59041656936943f5bee12fbb2b585a27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/38 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '5f62f9'. Skipping!\n",
            "Property 'summary' already exists in node '9e619d'. Skipping!\n",
            "Property 'summary' already exists in node '585552'. Skipping!\n",
            "Property 'summary' already exists in node '75a48b'. Skipping!\n",
            "Property 'summary' already exists in node '3fc6fa'. Skipping!\n",
            "Property 'summary' already exists in node '7a85bf'. Skipping!\n",
            "Property 'summary' already exists in node 'f1a0dd'. Skipping!\n",
            "Property 'summary' already exists in node 'e5c7ad'. Skipping!\n",
            "Property 'summary' already exists in node '38c096'. Skipping!\n",
            "Property 'summary' already exists in node '2ea688'. Skipping!\n",
            "Property 'summary' already exists in node '02cb4d'. Skipping!\n",
            "Property 'summary' already exists in node 'f4b3b0'. Skipping!\n",
            "Property 'summary' already exists in node 'e8b8c5'. Skipping!\n",
            "Property 'summary' already exists in node 'c24658'. Skipping!\n",
            "Property 'summary' already exists in node '823495'. Skipping!\n",
            "Property 'summary' already exists in node '3d4517'. Skipping!\n",
            "Property 'summary' already exists in node '03c184'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faa12b5f4da645c094a9586fa78dc677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c125bd071a942ceb0e4119a7e549cea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/48 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '9e619d'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f1a0dd'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e5c7ad'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '38c096'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '3fc6fa'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '5f62f9'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '585552'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7a85bf'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '75a48b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '02cb4d'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '2ea688'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e8b8c5'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'f4b3b0'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c24658'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '823495'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '3d4517'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '03c184'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "269330085f514810a77fc6959ffa6201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2d2ccb0b10f4ba697ab652dda4df7c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "998ca92ec41e47db81a8b6725bd3aa13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d22a3818256249f692c5ac6adfb27cfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Kulveit et al., 2025 what they say about AI ch...</td>\n",
              "      <td>[Introduction ChatGPT launched in November 202...</td>\n",
              "      <td>The context mentions Kulveit et al., 2025 in r...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does OpenAI's development influence user i...</td>\n",
              "      <td>[Table 1: ChatGPT daily message counts (millio...</td>\n",
              "      <td>The context discusses that nearly 80% of all C...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Could you explain the significance of SOC2 cod...</td>\n",
              "      <td>[Variation by Occupation Figure 23 presents va...</td>\n",
              "      <td>Variation by Occupation Figure 23 presents var...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of Personal Reflectio...</td>\n",
              "      <td>[Conclusion This paper studies the rapid growt...</td>\n",
              "      <td>According to the context, Personal Reflection ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The data indicates that a significant portion ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the increasing percentage of non-work...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nMonth Non-Work (M) (%) Work (M) (%...</td>\n",
              "      <td>The data shows that non-work messages increase...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do usage patterns and growth across popula...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>The context indicates that ChatGPT's adoption ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nIntroduction ChatGPT launched in N...</td>\n",
              "      <td>The rapid adoption of ChatGPT, with over 18 bi...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Based on the findings of Handa et al. (2025), ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>what Handa et al 2025 say about ChatGPT messag...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nTable 1: ChatGPT daily message cou...</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Based on the data indicating that over 700 mil...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT h...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>what July 2025 data show ChatGPT use like, and...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nConclusion This paper studies the ...</td>\n",
              "      <td>In July 2025, ChatGPT had over 700 million wee...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Kulveit et al., 2025 what they say about AI ch...   \n",
              "1   How does OpenAI's development influence user i...   \n",
              "2   Could you explain the significance of SOC2 cod...   \n",
              "3   What is the significance of Personal Reflectio...   \n",
              "4   Considering the rapid growth of ChatGPT's usag...   \n",
              "5   How does the increasing percentage of non-work...   \n",
              "6   How do usage patterns and growth across popula...   \n",
              "7   Considering the rapid growth of ChatGPT's usag...   \n",
              "8   Based on the findings of Handa et al. (2025), ...   \n",
              "9   what Handa et al 2025 say about ChatGPT messag...   \n",
              "10  Based on the data indicating that over 700 mil...   \n",
              "11  what July 2025 data show ChatGPT use like, and...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Introduction ChatGPT launched in November 202...   \n",
              "1   [Table 1: ChatGPT daily message counts (millio...   \n",
              "2   [Variation by Occupation Figure 23 presents va...   \n",
              "3   [Conclusion This paper studies the rapid growt...   \n",
              "4   [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "5   [<1-hop>\\n\\nMonth Non-Work (M) (%) Work (M) (%...   \n",
              "6   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "7   [<1-hop>\\n\\nIntroduction ChatGPT launched in N...   \n",
              "8   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "9   [<1-hop>\\n\\nTable 1: ChatGPT daily message cou...   \n",
              "10  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "11  [<1-hop>\\n\\nConclusion This paper studies the ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The context mentions Kulveit et al., 2025 in r...   \n",
              "1   The context discusses that nearly 80% of all C...   \n",
              "2   Variation by Occupation Figure 23 presents var...   \n",
              "3   According to the context, Personal Reflection ...   \n",
              "4   The data indicates that a significant portion ...   \n",
              "5   The data shows that non-work messages increase...   \n",
              "6   The context indicates that ChatGPT's adoption ...   \n",
              "7   The rapid adoption of ChatGPT, with over 18 bi...   \n",
              "8   Handa et al. (2025) report that nearly 80% of ...   \n",
              "9   Handa et al. (2025) report that nearly 80% of ...   \n",
              "10  The context shows that by July 2025, ChatGPT h...   \n",
              "11  In July 2025, ChatGPT had over 700 million wee...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vSRr2MXk0P_"
      },
      "source": [
        "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLDUsLJg43k7"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLtk1GtnyoY"
      },
      "source": [
        "## Task 4: LangSmith Dataset\n",
        "\n",
        "Now we can move on to creating a dataset for LangSmith!\n",
        "\n",
        "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
        "\n",
        "We'll name our Dataset to make it easy to work with later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TLgm6OjvYSsm"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"Use Case Synthetic Data - AIE8\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Synthetic Data for Use Cases\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64SmXMBnzXWm"
      },
      "source": [
        "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
        "\n",
        "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8nFQ6di_XnY7"
      },
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EbQVyZq-2j"
      },
      "source": [
        "## Basic RAG Chain\n",
        "\n",
        "Time for some RAG!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4njbUAIsaYjB"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQorBy8H1AZR"
      },
      "source": [
        "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qWo3Ajaragv1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghuTb9R01oO"
      },
      "source": [
        "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UwfJCzP3aqKI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpCLS-a01Ft2"
      },
      "source": [
        "As usual, we will power our RAG application with Qdrant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "58Ypj_NgbEsi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SbKSjfSkbTYo"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxUOMaQX1K2N"
      },
      "source": [
        "To get the \"A\" in RAG, we'll provide a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1sLeY1oWbVqO"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnHDh4e1Ou5"
      },
      "source": [
        "As is usual: We'll be using `gpt-4.1-mini` for our RAG!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6nx-ue1XbciV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTL6-pc1ZGz"
      },
      "source": [
        "Finally, we can set-up our RAG LCEL chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TjWj0OLIbbFc"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQ7bEweo4IIb",
        "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, people are using AI, particularly generative AI like ChatGPT, in a variety of ways including:\\n\\n- Performing workplace tasks, either augmenting or automating human labor.\\n- Producing writing, software code, spreadsheets, and other digital products.\\n- Seeking information and advice, similar to traditional web search engines but with more flexibility.\\n- Using AI as co-workers producing output or as co-pilots giving advice and improving human problem-solving productivity.\\n- Engaging in activities related to relationships, personal reflection, games, and role play, though these are a smaller share of usage.\\n- Therapy and companionship are also noted as prevalent use cases for generative AI.\\n\\nOverall, generative AI is highly flexible and is used both for professional purposes such as labor and decision-making, and for personal purposes such as self-expression and companionship.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What are people doing with AI these days?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9hBh5YPrdGJ"
      },
      "source": [
        "## LangSmith Evaluation Set-up\n",
        "\n",
        "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gfwPYdIkcvpF"
      },
      "outputs": [],
      "source": [
        "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8pToKH2K28"
      },
      "source": [
        "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PXSG-_ajckp6"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": (\n",
        "                \"Is this submission helpful to the user,\"\n",
        "                \" taking into account the correct reference answer?\"\n",
        "            )\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    },\n",
        "    prepare_data=lambda run, example: {\n",
        "        \"prediction\": run.outputs[\"output\"],\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "dopeness_evaluator = LangChainStringEvaluator(\n",
        "    \"criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"dopeness\": \"Is this response dope, lit, cool, or is it just a generic response?\",\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0SQP_FoCetP"
      },
      "source": [
        "#### 🏗️ Activity #2:\n",
        "\n",
        "Highlight what each evaluator is evaluating.\n",
        "\n",
        "- `qa_evaluator`: evaluates the quality of question-answer pairs -> \"How well is our RAG system answering questions\" It checks\n",
        "  - **The answer quality**: How good is the generated answer.\n",
        "  - **Relevance**: Does the answer actually address the question?\n",
        "  - **Completeness**: Is the answer complete and informative?\n",
        "  - **Accuracy**: Is the answer factually correct?\n",
        "\n",
        "- `labeled_helpfulness_evaluator`: evaluates if the answer is helpful to the user.\n",
        "- `dopeness_evaluator`: evaluates how \"dope\" or \"cool\" the answer is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35sQMHVrnpl"
      },
      "source": [
        "## LangSmith Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "122b1bd1f0e9417a8dcb57d4eebe4d2e",
            "e0c233ad01604540a6c873f4a731982d",
            "e9a01115c75b499884f7e0ef32e9e599",
            "5faba4ad609448b2b49024add4ad3b8e",
            "ef25efa751304e4699910f1fbc14345f",
            "0b44cb0f8e34446c8dde668a75d3d8ad",
            "edaac6587b2d4bd5be52b89bb097f99f",
            "7cb241365f604419af454c1c28de197a",
            "9cf586576ff44dba86ba2eb389593c61",
            "849b5c95008541d49f1ceedf0a59ac60",
            "f3665a86662746c4ac7cb0796604781d"
          ]
        },
        "id": "t7t_Uz0tdumL",
        "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'fresh-detail-16' at:\n",
            "https://smith.langchain.com/o/54cd3916-cf32-4735-9053-ad02339e1abb/datasets/d9f59057-5dde-4610-b0b5-85fc4c9f7549/compare?selectedSessions=2f0bbd8a-d506-42ee-ab94-38a8c6171787\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86e40e0d4e0940859383dc9feed1f488",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what July 2025 data show ChatGPT use like, and...</td>\n",
              "      <td>By July 2025, ChatGPT had more than 700 millio...</td>\n",
              "      <td>None</td>\n",
              "      <td>In July 2025, ChatGPT had over 700 million wee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.497519</td>\n",
              "      <td>747940ab-46fb-44cd-bae8-27ccf2ff0875</td>\n",
              "      <td>57f50fab-e332-4c06-b4d0-ee85c5508ea3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Based on the data indicating that over 700 mil...</td>\n",
              "      <td>Based on the provided context, the widespread ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT h...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.725201</td>\n",
              "      <td>89fb0173-2ce7-42ad-b075-4a055a5b34ff</td>\n",
              "      <td>1c3f5d67-7b12-45b9-a438-13817b0a9289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what Handa et al 2025 say about ChatGPT messag...</td>\n",
              "      <td>Handa et al. (2025) are mentioned in the conte...</td>\n",
              "      <td>None</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.804315</td>\n",
              "      <td>e76d8c70-f9a1-4088-81e8-45c2c31b9156</td>\n",
              "      <td>16d28117-bcb5-4f30-afd5-7a8979cf4ffa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Based on the findings of Handa et al. (2025), ...</td>\n",
              "      <td>Based on the context provided, the 2025 study ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.289896</td>\n",
              "      <td>24f60c41-7ee4-487f-b6de-24977c773987</td>\n",
              "      <td>22932ffd-3918-4c50-87b7-0929657b82cf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>Based on the provided context, the analysis us...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid adoption of ChatGPT, with over 18 bi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.741153</td>\n",
              "      <td>e92463db-b06c-434c-86fa-79d6eff672ba</td>\n",
              "      <td>5c952963-89c3-4878-bf75-10c52575636a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do usage patterns and growth across popula...</td>\n",
              "      <td>Based on the provided context, usage patterns ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context indicates that ChatGPT's adoption ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.417308</td>\n",
              "      <td>de7dcde9-f91f-408f-bc2a-4446a1cf85c0</td>\n",
              "      <td>0793737d-f274-4045-be82-96e38504f534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the increasing percentage of non-work...</td>\n",
              "      <td>Based on the provided context, the proportion ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The data shows that non-work messages increase...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.644545</td>\n",
              "      <td>87e21c66-c293-453d-9ff6-a567b3b32e73</td>\n",
              "      <td>085174bc-ed5c-4d9f-8074-724c118e31f6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>None</td>\n",
              "      <td>The data indicates that a significant portion ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.806713</td>\n",
              "      <td>71939f95-13fe-4731-8c04-1c9c8a2ca6b7</td>\n",
              "      <td>80679a06-eb19-44b7-89f6-620eaffd9409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the significance of Personal Reflectio...</td>\n",
              "      <td>Based on the provided context, Personal Reflec...</td>\n",
              "      <td>None</td>\n",
              "      <td>According to the context, Personal Reflection ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.090913</td>\n",
              "      <td>2118fe57-7aee-4432-8fb3-06335972010b</td>\n",
              "      <td>947e3e30-698b-4eaa-9346-6e30a832bcd0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Could you explain the significance of SOC2 cod...</td>\n",
              "      <td>Based on the provided context:\\n\\nSOC2 code 13...</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation by Occupation Figure 23 presents var...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.577661</td>\n",
              "      <td>650a4f17-8cb9-40b1-b9b0-c3af9dc2eeb0</td>\n",
              "      <td>aa4708da-c0c4-4ab7-97ca-11dbd3906370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does OpenAI's development influence user i...</td>\n",
              "      <td>Based on the provided context, OpenAI's develo...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context discusses that nearly 80% of all C...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5.329413</td>\n",
              "      <td>91d82119-6e6c-4c35-b0e1-2cd1e5853279</td>\n",
              "      <td>f581bcb0-f7e8-4be9-b69f-c6c8747d3709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kulveit et al., 2025 what they say about AI ch...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>None</td>\n",
              "      <td>The context mentions Kulveit et al., 2025 in r...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.995963</td>\n",
              "      <td>b18106ae-7a1c-42a5-83c5-0785310075fa</td>\n",
              "      <td>e9e7686c-dd5f-42c9-8263-a829e55a1590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults fresh-detail-16>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"default_chain_init\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7fCVinrpI4"
      },
      "source": [
        "## Dope-ifying Our Application\n",
        "\n",
        "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
        "\n",
        "- Include a \"dope\" prompt augmentation\n",
        "- Use larger chunks\n",
        "- Improve the retriever model to: `text-embedding-3-large`\n",
        "\n",
        "Let's see how this changes our evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "z56pXwyUgFUt"
      },
      "outputs": [],
      "source": [
        "DOPENESS_RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Make your answer rad, ensure high levels of dopeness. Do not be generic, or give generic responses.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "dopeness_rag_prompt = ChatPromptTemplate.from_template(DOPENESS_RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rZLcTstJgfv5"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "-LYsyirngj6n"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spldiPuTCzDO"
      },
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "Why would modifying our chunk size modify the performance of our application?\n",
        "\n",
        "#### ✅ Answer #2:\n",
        "\n",
        "By changing the chunk size (in our case: making it bigger), the amount of information per chunk changes. Smaller chunks have more focused information, but relationships between information or their 'context' might get lost. Bigger chunks can preserve relationships between information better, but can also include irrelevant information that dilutes the context.\n",
        "\n",
        "We have 50% single-hop questions and 50% multi-hop questions. Single-hop questions might perform better with smaller chunk sizes, while multi-hop (especially abstract multi-hop) questions might benefit more from larger chunks. So it is hard to tell if the increase in chunk size will increase the performance or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "b9MI2Bm2go1r"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBbjG6cKC8BQ"
      },
      "source": [
        "#### ❓Question #3:\n",
        "\n",
        "Why would modifying our embedding model modify the performance of our application?\n",
        "\n",
        "#### ✅ Answer #3:\n",
        "\n",
        "A better embedding model results in more relevant content being retrieved, which helps the LLM to return better answers. The text-embedding-3-large model has higher dimensional vectors that capture semantic meaning more accurately than text-embedding-3-small. This means it can better understand relationships between concepts and find more relevant chunks when performing similarity searches. So in our case, going from text-embedding-3-small to text-embedding-3-large should definitely improve the performance of our application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hVUY25FKgxXx"
      },
      "outputs": [],
      "source": [
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Use Case RAG Docs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Q4TOZNYIg2v1"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYGFrnKDB91"
      },
      "source": [
        "Setting up our new and improved DOPE RAG CHAIN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "HqnTqeXMhAdx"
      },
      "outputs": [],
      "source": [
        "dopeness_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | dopeness_rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pTxoqJDI1Y"
      },
      "source": [
        "Let's test it on the same output that we saw before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OfZZ3MoN3fKv",
        "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Alright, strap in—the AI money game is more lit than you thought. The context drops some serious knowledge bombs on how ChatGPT and generative AI are flipping the script in the money-making arena.\\n\\nFirst off, peeps aren’t just using AI to clock in and grind on mundane tasks. Nah, that’s old news. The real sauce is AI acting as a **smart advisor and research assistant**—boosting decision-making, firing up productivity, and unleashing worker output like a productivity beast on steroids.\\n\\nCollis and Brynjolfsson (2025) put a number on this magic: US users would demand a cool $98 each just to *pause* using generative AI for a month. That’s a jaw-dropping **$97 billion a year in consumer surplus**. Translation? AI’s not just helping people earn—it's creating insane value and economic surplus just by being their confidential sidekick at work and beyond.\\n\\nSo, the money moves come from:\\n- **Augmenting human labor** (not just replacing it)\\n- Giving **decision support and research boost**\\n- Supercharging productivity so humans hit way better output than solo grind\\n- Creating vast economic value that’s basically a tidal wave of new cash flow\\n\\nNo generic chatter here—AI is a turbocharged sidekick turning brainpower into cold hard cash, blowing the doors off traditional work roles and opening new avenues for making bank.\\n\\nIn short: people are using AI as their ultimate hustle partner, not just a tool, unleashing waves of productivity, smart insights, and economic gains that translate into massive moolah. Boom! 💸💥\""
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dopeness_rag_chain.invoke({\"question\" : \"How are people using AI to make money?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpj7v1inDLnQ"
      },
      "source": [
        "Finally, we can evaluate the new chain on the same test set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bf8dcc0895054529af356da401c513f6",
            "7dce19ac55264f2b88a0e4730e55867b",
            "2a0755d4476543feb4a64538e3e37213",
            "158212a630f04cbd884c937f2f60f5c8",
            "11c7f66acc1d45be9517d0addf49331e",
            "ddffd834e09940a4bd3874c3f39b4e21",
            "ef63c3b2d51e452da03cdae5d9b034be",
            "c20b539cd70b4ba99601ad1d69fd9cec",
            "a6d681eeafa44d18b933a4c5dec88382",
            "d1d54ccd56494c4d831f71b416a1f880",
            "530f696feefe499da08c6312047379b2"
          ]
        },
        "id": "Dx11S2b-hIM8",
        "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'best-pen-78' at:\n",
            "https://smith.langchain.com/o/54cd3916-cf32-4735-9053-ad02339e1abb/datasets/d9f59057-5dde-4610-b0b5-85fc4c9f7549/compare?selectedSessions=198733f6-c00c-4339-b4e5-34d249a63a8d\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7edc12d329ee4dc7b89557f61fc186fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.dopeness</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what July 2025 data show ChatGPT use like, and...</td>\n",
              "      <td>Yo, the July 2025 data on ChatGPT is straight ...</td>\n",
              "      <td>None</td>\n",
              "      <td>In July 2025, ChatGPT had over 700 million wee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.087465</td>\n",
              "      <td>747940ab-46fb-44cd-bae8-27ccf2ff0875</td>\n",
              "      <td>e3ec9c87-5b8a-49c9-88a5-7dec1ca16f56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Based on the data indicating that over 700 mil...</td>\n",
              "      <td>Yo, this data is straight fire! By July 2025, ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context shows that by July 2025, ChatGPT h...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.324843</td>\n",
              "      <td>89fb0173-2ce7-42ad-b075-4a055a5b34ff</td>\n",
              "      <td>502750fe-f1de-47bd-bef3-a7af7427bdcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what Handa et al 2025 say about ChatGPT messag...</td>\n",
              "      <td>Alright, diving into the vortex of pure data a...</td>\n",
              "      <td>None</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.784174</td>\n",
              "      <td>e76d8c70-f9a1-4088-81e8-45c2c31b9156</td>\n",
              "      <td>7cc88efe-921e-4d8f-b7e4-ccf4269d6338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Based on the findings of Handa et al. (2025), ...</td>\n",
              "      <td>Alright, let’s blast off with some turbocharge...</td>\n",
              "      <td>None</td>\n",
              "      <td>Handa et al. (2025) report that nearly 80% of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.097683</td>\n",
              "      <td>24f60c41-7ee4-487f-b6de-24977c773987</td>\n",
              "      <td>fd7557f8-7dbc-46a1-8438-011165a82d63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>Yo, here’s the rad lowdown straight from the c...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rapid adoption of ChatGPT, with over 18 bi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.955903</td>\n",
              "      <td>e92463db-b06c-434c-86fa-79d6eff672ba</td>\n",
              "      <td>bc4e6fda-5efd-4815-b86d-286c3529c52e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do usage patterns and growth across popula...</td>\n",
              "      <td>Alright, strap in for the lowdown on ChatGPT’s...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context indicates that ChatGPT's adoption ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.841068</td>\n",
              "      <td>de7dcde9-f91f-408f-bc2a-4446a1cf85c0</td>\n",
              "      <td>8ac22a9e-cd0d-490f-8156-1b9b8c00cb57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the increasing percentage of non-work...</td>\n",
              "      <td>Yo, here’s the dopest breakdown straight from ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The data shows that non-work messages increase...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.416976</td>\n",
              "      <td>87e21c66-c293-453d-9ff6-a567b3b32e73</td>\n",
              "      <td>aca9a85a-660c-4e26-9413-2741a6422851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Considering the rapid growth of ChatGPT's usag...</td>\n",
              "      <td>Alright, strap in — let’s ride this AI wave wi...</td>\n",
              "      <td>None</td>\n",
              "      <td>The data indicates that a significant portion ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6.009318</td>\n",
              "      <td>71939f95-13fe-4731-8c04-1c9c8a2ca6b7</td>\n",
              "      <td>30f4f451-7490-4e79-9fc3-aed3f6072c76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the significance of Personal Reflectio...</td>\n",
              "      <td>Alright, let’s slice through the data like a c...</td>\n",
              "      <td>None</td>\n",
              "      <td>According to the context, Personal Reflection ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.982689</td>\n",
              "      <td>2118fe57-7aee-4432-8fb3-06335972010b</td>\n",
              "      <td>32d9cd7a-44bc-4310-bd62-5feeea564177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Could you explain the significance of SOC2 cod...</td>\n",
              "      <td>Alright, let's unpack this with maximum swagge...</td>\n",
              "      <td>None</td>\n",
              "      <td>Variation by Occupation Figure 23 presents var...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.155683</td>\n",
              "      <td>650a4f17-8cb9-40b1-b9b0-c3af9dc2eeb0</td>\n",
              "      <td>77c20dba-a765-46cb-99bd-36206d116653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does OpenAI's development influence user i...</td>\n",
              "      <td>Alright, listen up—here’s the ultra-dopeness o...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context discusses that nearly 80% of all C...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.420152</td>\n",
              "      <td>91d82119-6e6c-4c35-b0e1-2cd1e5853279</td>\n",
              "      <td>a958cd5a-d9de-48d7-8491-f18d81fe4119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kulveit et al., 2025 what they say about AI ch...</td>\n",
              "      <td>Yo, I scoured the cosmic depths of the provide...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context mentions Kulveit et al., 2025 in r...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.974122</td>\n",
              "      <td>b18106ae-7a1c-42a5-83c5-0785310075fa</td>\n",
              "      <td>ece19d50-c621-4f5f-bd79-8b9b0e3e43f2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults best-pen-78>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    dopeness_rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        dopeness_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"dopeness_rag_chain\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7migvlDPZT"
      },
      "source": [
        "#### 🏗️ Activity #3:\n",
        "\n",
        "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways.\n",
        "\n",
        "### Analysis:\n",
        "\n",
        "The system performed better in Test 2 with the larger chunk size and the better embedding model. Especially for 'Helpfulness,' it performed dramatically better (0.4167 vs. 0.833). For correctness, there was no difference in numbers (both had 10 out of 12 correct).\n",
        "\n",
        "What did change, though, is that in Test 1 there were two 'I don't know' answers, while in Test 2 the answers were actually wrong. This means the system went from being conservative (saying 'I don't know') in Test 1 to being overconfident (giving wrong answers). This suggests the improvements made the system more likely to find information, but not always the correct information.\n",
        "\n",
        "However, we changed two parameters at the same time: chunk size and the embedding model. This makes it harder to identify which of these changes had the biggest impact. It was to be expected that the results would be better because of the better embedding model, but we could not see what effect the increase in chunk size had. It could also be possible that the results would be even better with the smaller chunk size and the better embedding model.\n",
        "\n",
        "That is why I did a third evaluation run with the smaller chunk size but the better model. It turned out that the correctness number did not change. We also had two wrong answers (instead of two non-answers), which suggests that the overconfidence was caused by the better embedding model. What did change was the 'Helpfulness' number - down from 0.833 to 0.75. So the chunk size did have a small impact, but not as much as the better model.\n",
        "\n",
        "'Dopeness' went from 0 to 1, but this was to be expected. This factor should not affect the result quality because it changes just the tone of the response.\n",
        "\n",
        "| Test       | Chunk Size | Embedding | Correctness | Helpfulness | Dopeness |\n",
        "| ---------- | ---------- | --------- | ----------- | ----------- | -------- |\n",
        "| **Test 1** | 500        | 3-small   | 83%         | 33%         | 0%       |\n",
        "| **Test 2** | 1000       | 3-large   | 83%         | 83%         | 100%      |\n",
        "| **Test 3** | 500        | 3-large   | 83%         | 75%         | 100%      |\n",
        "\n",
        "\n",
        "Here are the tests:\n",
        "\n",
        "Test 1:\n",
        "\n",
        "![image](img/langsmith-eval-1.png)\n",
        "\n",
        "Test 2:\n",
        "\n",
        "![image](img/langsmith-eval-2.png)\n",
        "\n",
        "Test 3:\n",
        "\n",
        "![image](img/langsmith-eval-3.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07ab3dc0790241bbb85a7f488a42ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
              "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
              "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
            ],
            "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
          }
        },
        "095f680d37a3430fb82d223615662db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b44cb0f8e34446c8dde668a75d3d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10df31709059484c99f102453d780473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1160a44dc18e47b0890f70c40eaa7eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c7f66acc1d45be9517d0addf49331e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
              "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
              "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
            ],
            "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
          }
        },
        "158212a630f04cbd884c937f2f60f5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
            "placeholder": "​",
            "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
            "value": " 20/? [01:43&lt;00:00,  5.25s/it]"
          }
        },
        "23863bc37a8645029934b8c106622c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2508d229935744cbb5fc340222e2d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a0755d4476543feb4a64538e3e37213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
            "value": 1
          }
        },
        "33f063017b7c4c7fa8cbafc89674350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
              "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
              "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
            ],
            "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
          }
        },
        "3a8537e37fc14fd9b16ca0ceee4fede6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bdd49fab5f4826959d0d50663ff539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
            "value": 64
          }
        },
        "530f696feefe499da08c6312047379b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d6e269eadf429a924f6f79bc8ba4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
            "value": 20
          }
        },
        "5ab5f08afa5841709aedb2f78a52a11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2fda99d4204d85b1bf7ad354fd58d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faba4ad609448b2b49024add4ad3b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
            "placeholder": "​",
            "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
            "value": " 20/? [01:27&lt;00:00,  6.45s/it]"
          }
        },
        "60168d85131d4afc99d55d61ab954ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
            "placeholder": "​",
            "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
            "value": " 61/64 [00:02&lt;00:00, 23.36it/s]"
          }
        },
        "61b52ff459214129b8f7e6d67b192b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6864c81e2bcf459bbaf5acbb36bdfcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
            "placeholder": "​",
            "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
            "value": "Generating: 100%"
          }
        },
        "6eb8b2e3262c45248708a2082c366f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710c7377cbc4c30b55b28b4bc99e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
            "placeholder": "​",
            "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
            "value": "embedding nodes:  95%"
          }
        },
        "7cb241365f604419af454c1c28de197a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7dce19ac55264f2b88a0e4730e55867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
            "placeholder": "​",
            "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
            "value": ""
          }
        },
        "849b5c95008541d49f1ceedf0a59ac60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890e0dd7fa524ceca1e805cb6253ee71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baf0ed3d0f743f294e07f2b5407e820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cd4d35c5fd41f5904ca1d52d1f52a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf586576ff44dba86ba2eb389593c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9edf898aeeab40dda9b9475395776521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a6d681eeafa44d18b933a4c5dec88382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8dcc0895054529af356da401c513f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
              "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
              "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
            ],
            "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
          }
        },
        "c20b539cd70b4ba99601ad1d69fd9cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca791fc471e34b9da2f9070fc1053c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
            "placeholder": "​",
            "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
            "value": " 20/20 [00:52&lt;00:00,  4.50s/it]"
          }
        },
        "d1d54ccd56494c4d831f71b416a1f880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddffd834e09940a4bd3874c3f39b4e21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c233ad01604540a6c873f4a731982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
            "value": ""
          }
        },
        "e9a01115c75b499884f7e0ef32e9e599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
            "value": 1
          }
        },
        "edaac6587b2d4bd5be52b89bb097f99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef25efa751304e4699910f1fbc14345f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef63c3b2d51e452da03cdae5d9b034be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3665a86662746c4ac7cb0796604781d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
