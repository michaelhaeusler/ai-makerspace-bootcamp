{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/z0/fq321gxs1hsgw09n91nz0bnm0000gn/T/ipykernel_83590/1203815797.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?\n",
        "\n",
        "#### ‚úÖ Answer #1:\n",
        "\n",
        "Each tool has a name, a description of its functionality (in natural language) and a JSON schema. Based on the context and the tool descriptions and the JSON data the LLM will choose the right tool from the toolbelt. So the better and clearer the tool descriptions, the more reliably it picks the right tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11843aa50>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11843aa50>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11843aa50>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11843aa50>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?\n",
        "\n",
        "#### ‚úÖ Answer #2\n",
        "\n",
        "No, there is no specific limit to how many times we can cycle. To impose a limit we could define a MAX_CYCLE_NUM in the `should_continue` edge and check the number of message and stop it if the MAX_CYCLE_NUM is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Technical professionals are using AI in various ways to enhance their work, including automating repetitive tasks, improving decision-making, analyzing large datasets, developing new products and services, and optimizing processes. They leverage AI for tasks such as machine learning model development, natural language processing, computer vision, predictive analytics, and automation of workflows. This integration helps increase efficiency, accuracy, and innovation across different industries. Would you like specific examples or insights into particular fields?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 163, 'total_tokens': 253, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLcT1cx44TjpXsWr5goU0O8jLCTPt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9c6f6a6-600b-4f01-b98a-8d9905baa25d-0', usage_metadata={'input_tokens': 163, 'output_tokens': 90, 'total_tokens': 253, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_340v9XNM2WxPyJjK05XuARoW', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_ac4WXVuv8Pb4Om97JZ2let4X', 'function': {'arguments': '{\"query\": \"author of A Comprehensive Survey of Deep Research\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 182, 'total_tokens': 242, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLcT5AUi9vVpmmS2vvpgs1gpy0vc8', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d192e256-0028-4d93-a6b1-1cc57051b937-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_340v9XNM2WxPyJjK05XuARoW', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'author of A Comprehensive Survey of Deep Research'}, 'id': 'call_ac4WXVuv8Pb4Om97JZ2let4X', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 60, 'total_tokens': 242, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='a8be2e39-9994-4e43-b017-99318494d9c3', tool_call_id='call_340v9XNM2WxPyJjK05XuARoW'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\\\\n\\\\n View PDF\\\\n HTML (experimental)\\\\n TeX Source\\\\n Other Formats\\\\n\\\\nview license\\\\n\\\\nCurrent browse context:\\\\n\\\\ncs.AI\\\\n\\\\n< prev\\\\\")    |    next >\\\\\")\\\\n\\\\nnew  |  recent  | 2025-06\\\\n\\\\nChange to browse by:\\\\n\\\\ncs cs.MA\\\\n\\\\n### References & Citations\\\\n\\\\n NASA ADS\\\\n Google Scholar\\\\n Semantic Scholar\\\\n\\\\na export BibTeX citation Loading...\\\\n\\\\n## BibTeX formatted citation\\\\n\\\\n√ó\", \"score\": 0.90289277}, {\"title\": \"A Comprehensive Survey of Deep Research: Systems ... - alphaXiv\", \"url\": \"https://www.alphaxiv.org/overview/2506.12594\", \"content\": \"This comprehensive survey by Renjun Xu and Jingwen Peng from Zhejiang University addresses the rapidly emerging field of Deep Research systems‚ÄîAI-powered applications that integrate large language models, advanced information retrieval, and autonomous reasoning to automate complex research workflows. The paper establishes the first systematic framework for understanding this domain, which has evolved dramatically since 2023, encompassing over 80 commercial and open-source implementations. [...] This paper is cited in the introduction to establish the high-level significance and transformative potential of the survey\\'s topic. It argues that human-aware AI can accelerate science by augmenting researchers\\' capabilities, providing a foundational conceptual motivation for the development of Deep Research systems.\\\\n\\\\nJamshid Sourati and James Evans. 2023. Accelerating science with human-aware artificial intelligence. arXiv:2306.01495 [cs.AI] [...] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. 2023. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. arXiv:2307.16789 [cs.AI] \\\\n\\\\nHumanity‚Äôs Last Exam\", \"score\": 0.838376}, {\"title\": \"A Comprehensive Survey on Deep Clustering - ACM Digital Library\", \"url\": \"https://dl.acm.org/doi/10.1145/3689036\", \"content\": \"You can change or withdraw your consent from the Cookie Declaration on our website at any time by visiting the Cookie Declaration page. If contacting us regarding your consent, please state your consent ID and date from that page.\\\\n\\\\nskip to main content\\\\n\\\\n# A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions\\\\n\\\\nAuthors: Sheng Zhou\\\\n\\\\nSheng Zhou\\\\n\\\\nZhejiang University, Hangzhou, China\\\\n\\\\nView Profile\\\\n\\\\n, Hongjia Xu\\\\n\\\\nHongjia Xu\\\\n\\\\nZhejiang University, Hangzhou, China [...] Wenwu Zhu\\\\n\\\\nTsinghua University, Beijing, China\\\\n\\\\nView Profile\\\\n\\\\n, Martin Ester\\\\n\\\\nMartin Ester\\\\n\\\\nSimon Fraser University, Burnaby, Canada\\\\n\\\\nView Profile\\\\n\\\\n (Less)Authors Info & Claims\\\\n\\\\nACM Computing Surveys, Volume 57, Issue 3\\\\n\\\\nArticle No.: 69, Pages 1 - 38\\\\n\\\\nPublished: 11 November 2024 Publication History\\\\n\\\\nMetrics\\\\n\\\\nTotal Citations23Total Downloads3,013\\\\n\\\\nLast 12 Months3,013\\\\n\\\\nLast 6 weeks205\\\\n\\\\nGet Access\\\\n\\\\n## Abstract [...] View Profile\\\\n\\\\n, Zhuonan Zheng\\\\n\\\\nZhuonan Zheng\\\\n\\\\nZhejiang University, Hangzhou, China\\\\n\\\\nView Profile\\\\n\\\\n, Jiawei Chen\\\\n\\\\nJiawei Chen\\\\n\\\\nZhejiang University, Hangzhou, China\\\\n\\\\nView Profile\\\\n\\\\n, + 6, Zhao Li\\\\n\\\\nZhao Li\\\\n\\\\nZhejiang University, Hangzhou, China\\\\n\\\\nView Profile\\\\n\\\\n, Jiajun Bu\\\\n\\\\nJiajun Bu\\\\n\\\\nZhejiang University, Hangzhou, China\\\\n\\\\nView Profile\\\\n\\\\n, + 4, Jia Wu\\\\n\\\\nJia Wu\\\\n\\\\nMacquarie University, Sydney, Australia\\\\n\\\\nView Profile\\\\n\\\\n, Xin Wang\\\\n\\\\nXin Wang\\\\n\\\\nTsinghua University, Beijing, China\\\\n\\\\nView Profile\\\\n\\\\n, Wenwu Zhu\", \"score\": 0.7166357}, {\"title\": \"A comprehensive survey of deep learning research on medical ...\", \"url\": \"https://pubmed.ncbi.nlm.nih.gov/36462229/\", \"content\": \"PMID: 36462229\\\\n    DOI: 10.1016/j.clinimag.2022.11.003\\\\n\\\\n Item in Clipboard \\\\n\\\\nReview\\\\n\\\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\\\n\\\\nSema Atasever et al. Clin Imaging.2023 Feb.\\\\n\\\\nShow details\\\\n\\\\nDisplay options\\\\n\\\\n Display options \\\\n\\\\n Format \\\\n\\\\n Clin Imaging \\\\n\\\\nActions\\\\n\\\\n   Search in PubMed\\\\n   Search in NLM Catalog\\\\n   Add to Search\\\\n\\\\n. 2023 Feb:94:18-41.\\\\n\\\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\\\n\\\\n### Authors [...] A comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\\\n\\\\nSema Atasever1,Nuh Azginoglu2,Duygu Sinanc Terzi3,Ramazan Terzi4\\\\n\\\\n Affiliations  Expand \\\\n\\\\n### Affiliations [...] 4 Computer Engineering Department, Amasya University, Amasya, Turkey. Electronic address: ramazan.terzi@amasya.edu.tr.\", \"score\": 0.71425}, {\"title\": \"a-comprehensive-survey-of-deep-research-systems-methodologies ...\", \"url\": \"https://warwick.ac.uk/fac/cross_fac/eduport/edufund/projects/yang/projects/a-comprehensive-survey-of-deep-research-systems-methodologies-and-applications/\", \"content\": \"### Project Team\\\\n\\\\n#### Renjun Xu\\\\n\\\\nResearcher\\\\n\\\\n#### Jingwen Peng\\\\n\\\\nResearcher\\\\n\\\\n### Contact Information\\\\n\\\\nFor information about the paper, please contact the authors.\\\\n\\\\nAuthors: Renjun Xu, Jingwen Peng\\\\n\\\\nSource Publication: View Original PaperLink opens in a new window\\\\n\\\\nProject Contact: Dr. Jianhua Yang\\\\n\\\\nLLM Model Version: gpt-4o-mini-2024-07-18\\\\n\\\\nAnalysis Provider: Openai\\\\n\\\\n‚Üê Back to Projects\", \"score\": 0.7125728}]', name='tavily_search_results_json', id='f310a1be-6ec8-46e3-b22d-bf2c9164c166', tool_call_id='call_ac4WXVuv8Pb4Om97JZ2let4X', artifact={'query': 'author of A Comprehensive Survey of Deep Research', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research - arXiv', 'content': 'We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors [...] View a PDF of the paper titled A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications, by Renjun Xu and 1 other authors\\n\\n View PDF\\n HTML (experimental)\\n TeX Source\\n Other Formats\\n\\nview license\\n\\nCurrent browse context:\\n\\ncs.AI\\n\\n< prev\")    |    next >\")\\n\\nnew  |  recent  | 2025-06\\n\\nChange to browse by:\\n\\ncs cs.MA\\n\\n### References & Citations\\n\\n NASA ADS\\n Google Scholar\\n Semantic Scholar\\n\\na export BibTeX citation Loading...\\n\\n## BibTeX formatted citation\\n\\n√ó', 'score': 0.90289277, 'raw_content': None}, {'url': 'https://www.alphaxiv.org/overview/2506.12594', 'title': 'A Comprehensive Survey of Deep Research: Systems ... - alphaXiv', 'content': \"This comprehensive survey by Renjun Xu and Jingwen Peng from Zhejiang University addresses the rapidly emerging field of Deep Research systems‚ÄîAI-powered applications that integrate large language models, advanced information retrieval, and autonomous reasoning to automate complex research workflows. The paper establishes the first systematic framework for understanding this domain, which has evolved dramatically since 2023, encompassing over 80 commercial and open-source implementations. [...] This paper is cited in the introduction to establish the high-level significance and transformative potential of the survey's topic. It argues that human-aware AI can accelerate science by augmenting researchers' capabilities, providing a foundational conceptual motivation for the development of Deep Research systems.\\n\\nJamshid Sourati and James Evans. 2023. Accelerating science with human-aware artificial intelligence. arXiv:2306.01495 [cs.AI] [...] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. 2023. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. arXiv:2307.16789 [cs.AI] \\n\\nHumanity‚Äôs Last Exam\", 'score': 0.838376, 'raw_content': None}, {'url': 'https://dl.acm.org/doi/10.1145/3689036', 'title': 'A Comprehensive Survey on Deep Clustering - ACM Digital Library', 'content': 'You can change or withdraw your consent from the Cookie Declaration on our website at any time by visiting the Cookie Declaration page. If contacting us regarding your consent, please state your consent ID and date from that page.\\n\\nskip to main content\\n\\n# A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions\\n\\nAuthors: Sheng Zhou\\n\\nSheng Zhou\\n\\nZhejiang University, Hangzhou, China\\n\\nView Profile\\n\\n, Hongjia Xu\\n\\nHongjia Xu\\n\\nZhejiang University, Hangzhou, China [...] Wenwu Zhu\\n\\nTsinghua University, Beijing, China\\n\\nView Profile\\n\\n, Martin Ester\\n\\nMartin Ester\\n\\nSimon Fraser University, Burnaby, Canada\\n\\nView Profile\\n\\n (Less)Authors Info & Claims\\n\\nACM Computing Surveys, Volume 57, Issue 3\\n\\nArticle No.: 69, Pages 1 - 38\\n\\nPublished: 11 November 2024 Publication History\\n\\nMetrics\\n\\nTotal Citations23Total Downloads3,013\\n\\nLast 12 Months3,013\\n\\nLast 6 weeks205\\n\\nGet Access\\n\\n## Abstract [...] View Profile\\n\\n, Zhuonan Zheng\\n\\nZhuonan Zheng\\n\\nZhejiang University, Hangzhou, China\\n\\nView Profile\\n\\n, Jiawei Chen\\n\\nJiawei Chen\\n\\nZhejiang University, Hangzhou, China\\n\\nView Profile\\n\\n, + 6, Zhao Li\\n\\nZhao Li\\n\\nZhejiang University, Hangzhou, China\\n\\nView Profile\\n\\n, Jiajun Bu\\n\\nJiajun Bu\\n\\nZhejiang University, Hangzhou, China\\n\\nView Profile\\n\\n, + 4, Jia Wu\\n\\nJia Wu\\n\\nMacquarie University, Sydney, Australia\\n\\nView Profile\\n\\n, Xin Wang\\n\\nXin Wang\\n\\nTsinghua University, Beijing, China\\n\\nView Profile\\n\\n, Wenwu Zhu', 'score': 0.7166357, 'raw_content': None}, {'url': 'https://pubmed.ncbi.nlm.nih.gov/36462229/', 'title': 'A comprehensive survey of deep learning research on medical ...', 'content': 'PMID: 36462229\\n    DOI: 10.1016/j.clinimag.2022.11.003\\n\\n Item in Clipboard \\n\\nReview\\n\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\n\\nSema Atasever et al. Clin Imaging.2023 Feb.\\n\\nShow details\\n\\nDisplay options\\n\\n Display options \\n\\n Format \\n\\n Clin Imaging \\n\\nActions\\n\\n   Search in PubMed\\n   Search in NLM Catalog\\n   Add to Search\\n\\n. 2023 Feb:94:18-41.\\n\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\n\\n### Authors [...] A comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\n\\nSema Atasever1,Nuh Azginoglu2,Duygu Sinanc Terzi3,Ramazan Terzi4\\n\\n Affiliations  Expand \\n\\n### Affiliations [...] 4 Computer Engineering Department, Amasya University, Amasya, Turkey. Electronic address: ramazan.terzi@amasya.edu.tr.', 'score': 0.71425, 'raw_content': None}, {'url': 'https://warwick.ac.uk/fac/cross_fac/eduport/edufund/projects/yang/projects/a-comprehensive-survey-of-deep-research-systems-methodologies-and-applications/', 'title': 'a-comprehensive-survey-of-deep-research-systems-methodologies ...', 'content': '### Project Team\\n\\n#### Renjun Xu\\n\\nResearcher\\n\\n#### Jingwen Peng\\n\\nResearcher\\n\\n### Contact Information\\n\\nFor information about the paper, please contact the authors.\\n\\nAuthors: Renjun Xu, Jingwen Peng\\n\\nSource Publication: View Original PaperLink opens in a new window\\n\\nProject Contact: Dr. Jianhua Yang\\n\\nLLM Model Version: gpt-4o-mini-2024-07-18\\n\\nAnalysis Provider: Openai\\n\\n‚Üê Back to Projects', 'score': 0.7125728, 'raw_content': None}], 'response_time': 1.8, 'request_id': 'e53f0890-093e-4317-8255-6c6bd45941aa'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The research paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" was authored by Renjun Xu and Jingwen Peng. \\n\\nRenjun Xu is affiliated with Zhejiang University, and Jingwen Peng\\'s current affiliation is not explicitly mentioned in the search results. \\n\\nWould you like me to try to find Jingwen Peng\\'s current affiliation or do you have any other questions?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 2645, 'total_tokens': 2726, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLcTEifMBtxeUvfXQkQw4KSOsBIlG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4487b98f-2299-4ca1-b2f1-16b6eba7c4c2-0', usage_metadata={'input_tokens': 2645, 'output_tokens': 81, 'total_tokens': 2726, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer.\n",
        "\n",
        "- a HumanMessage is added to the messages list of the state object\n",
        "- the agent node adds an AIMessage to the state object with two tool_calls (i.e. function calls):\n",
        "  - arxiv(query=\"A Comprehensive Survey of Deep Research\")\n",
        "  - tavily_search_results_json(query=\"author of A Comprehensive Survey of Deep Research\")\n",
        "- the conditional edge sees tool_calls in the last message (from the agent) and routes to the action node\n",
        "- the action node executes the requested tools and adds the results (\"ToolMessages\") to the messages list\n",
        "- the graph routes back to the agent\n",
        "- the agent reads the tool results and creates the final answer (based on the tool results) -> this is a normal AIMessage without tool_calls\n",
        "- the conditional edge sees no tool_call this time and stopps (i.e. routes to the END node) and the run finishes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Deep Research generally refers to an in-depth and comprehensive investigation or analysis into a specific topic, subject, or field. It involves thorough data collection, critical evaluation, and detailed understanding to uncover insights, patterns, and knowledge that are not immediately obvious. Deep Research is often used in academic, scientific, technological, and business contexts to develop a profound understanding and to support decision-making, innovation, or discovery.\\n\\nIf you are referring to a specific organization, product, or platform named \"Deep Research,\" please provide more context so I can give a more precise answer.'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
        "\n",
        "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
        "    },\n",
        "    ...,\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "I am not sure if I got the quest task right i.e. which topic I should create the questions about. \n",
        "I now used the mentioned article \"How people use ChatGPT\" from OpenAI.\n",
        "\"\"\"\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"How do people use AI in their daily work?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"writing\", \"summarizing\", \"research\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"What are the most common ways people use AI in their work?\"\n",
        "        },\n",
        "        \"outputs\": {\"must_mention\": [\"Asking\", \"Doing\", \"Expressing\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"Do people use AI for their personal lives?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"70%\", \"non-work\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What concerns or challenges do people have when using AI?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"accuracy\", \"privacy\", \"bias\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"Who are the authors of the paper ‚ÄúHow People Use ChatGPT‚Äù?\"\n",
        "        },\n",
        "        \"outputs\": {\n",
        "            \"must_mention\": [\n",
        "                \"Chatterji\",\n",
        "                \"Cunningham\",\n",
        "                \"Deming\",\n",
        "                \"Hitzig\",\n",
        "                \"Ong\",\n",
        "                \"Shan\",\n",
        "                \"Wadman\",\n",
        "            ]\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"When was ChatGPT adoption data in the study measured (time period)?\"\n",
        "        },\n",
        "        \"outputs\": {\"must_mention\": [\"November 2022\", \"July 2025\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"Which three conversation topics collectively account for ~80 % of use according to the paper?\"\n",
        "        },\n",
        "        \"outputs\": {\n",
        "            \"must_mention\": [\"Practical Guidance\", \"Seeking Information\", \"Writing\"]\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"What share of conversations are non-work messages by mid-period?\"\n",
        "        },\n",
        "        \"outputs\": {\"must_mention\": [\"70%\", \"non-work\"]},\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\n",
        "            \"text\": \"Which user characteristic is associated with more work-related usage in the study?\"\n",
        "        },\n",
        "        \"outputs\": {\n",
        "            \"must_mention\": [\"educated\", \"professional occupation\", \"higher income\"]\n",
        "        },\n",
        "    },\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['0a387183-36ab-48a7-8b8e-837a0c399821',\n",
              "  '816bf913-5a46-4f27-8e1c-95e9684378c4',\n",
              "  'c77f011e-cf65-401f-b9f3-874e9ef3fd9c',\n",
              "  '0287aaba-0ce7-4269-9aeb-318f68aecc60',\n",
              "  '8118742b-4fca-47bd-b117-41ac8d71fa10',\n",
              "  '3cce21d3-9d1c-4958-953b-5141f93912ff',\n",
              "  'd07cfbae-ca9c-4520-8a6b-047a60581e0a',\n",
              "  '3a8a1289-07e6-4005-b5d4-0b16bc059d0f',\n",
              "  '6913ae90-6807-4c2a-8962-a32e09e2787f'],\n",
              " 'count': 9}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
        "\n",
        "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A correct answer:\n",
            "  - Provides accurate and complete information\n",
            "  - Contains no factual errors\n",
            "  - Addresses all parts of the question\n",
            "  - Is logically consistent\n",
            "  - Uses precise and accurate terminology\n",
            "\n",
            "  When scoring, you should penalize:\n",
            "  - Factual errors or inaccuracies\n",
            "  - Incomplete or partial answers\n",
            "  - Misleading or ambiguous statements\n",
            "  - Incorrect terminology\n",
            "  - Logical inconsistencies\n",
            "  - Missing key information\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output\n",
            "  - Check for factual accuracy and completeness\n",
            "  - Focus on correctness of information rather than style or verbosity\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to evaluate factual correctness and completeness of the response.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n",
            "Use the reference outputs below to help you evaluate the correctness of the response:\n",
            "\n",
            "<reference_outputs>\n",
            "{reference_outputs}\n",
            "</reference_outputs>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openevals.prompts import CORRECTNESS_PROMPT\n",
        "print(CORRECTNESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from openevals.llm import create_llm_as_judge\n",
        "\n",
        "correctness_evaluator = create_llm_as_judge(\n",
        "        prompt=CORRECTNESS_PROMPT,\n",
        "        model=\"openai:o3-mini\", # very impactful to the final score\n",
        "        feedback_key=\"correctness\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "  # determine if the phrases in the reference_outputs are in the outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ‚úÖ Answer #2\n",
        "\n",
        "The \"must_mention\" function could be improved by:\n",
        "- normalizing the texts (case, whitespace, removing punctuation, stardardize quotes, etc)\n",
        "- using regex (fraction match) instead of having to match the exact phrases\n",
        "- using a negative \"must_not_mention\" list as well\n",
        "- adding synonyms / aliases to the reference outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'simple_agent, baseline-1aead2f4' at:\n",
            "https://smith.langchain.com/o/54cd3916-cf32-4735-9053-ad02339e1abb/datasets/796bd110-739b-49e5-aa1a-b8146718154b/compare?selectedSessions=3e396aef-5281-4437-951f-8162a3fea366\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4a10c1090ca48d1ab767345fb6144f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    evaluators=[correctness_evaluator, must_mention],\n",
        "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
        "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
        "    max_concurrency=4, # optional, add concurrency\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rN7feNVn9f"
      },
      "source": [
        "As before we are creating a new graph called \"graph_with_helpfulness_check\" which we pass out created AgentState and add the 'agent' node (call_model) and our action node (tool_node) to our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r6XXA5FJbVf",
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ad096d0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ22o2mWVrfp"
      },
      "source": [
        "We then define the entry point for our graph which is the \"agent\" node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNWHwWxuRiLY",
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ad096d0>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "This `tool_call_or_helpful` function is a conditional edge. It checks the latest message. If it asks to use a tool, it routes to run the tool (\"action\"). If no tool is requested and the conversation is already long (>10 messages), it stops (\"END\").\n",
        "Otherwise, it asks a small model: ‚ÄúWas this answer helpful (Y/N)?‚Äù using the original question and current answer.\n",
        "If the model replies with ‚ÄúY‚Äù, it finishes (\"end\"); if not, it keeps going to improve the answer (\"continue\").   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "Now lets add the conditional edge `tool_call_or_helpful` to our graph. The last parameter (the dict) maps the return labels of the conditional edge to where to graph should go next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ad096d0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "Now we also have to connect the 'action' and the 'agent' nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11ad096d0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "The last step is to compile our graph so we can use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "Let's test our new graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Deep Research Agents are advanced AI systems designed to assist with complex research tasks. They leverage deep learning techniques and large datasets to analyze, synthesize, and generate insights across various fields of study. These agents can automate literature reviews, extract relevant information from vast sources, identify patterns, and even generate hypotheses or summaries to support researchers in their work. They are often used in scientific research, data analysis, and knowledge discovery to enhance efficiency and accuracy. Would you like a more detailed explanation or specific examples of Deep Research Agents?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 158, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLcTftRCGIa5D0tXHtuQYqAwBi0cO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8313aaf6-aa35-419e-adc7-a3f23107e072-0', usage_metadata={'input_tokens': 158, 'output_tokens': 104, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
        "\n",
        "Let's ask our system about the 3 main patterns in Generative AI:\n",
        "\n",
        "1. Context Engineering\n",
        "2. Fine-tuning\n",
        "3. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context Engineering is a relatively new interdisciplinary field that focuses on designing, managing, and optimizing the context in which systems, especially artificial intelligence and software applications, operate. It involves understanding and shaping the environment, circumstances, and background information that influence how systems behave and interact with users. The goal is to improve system performance, user experience, and decision-making by carefully engineering the context.\n",
            "\n",
            "The concept of Context Engineering gained prominence with the rise of context-aware computing and pervasive computing in the early 2000s. It became more widely recognized as a distinct area of study and practice around the mid-2010s, particularly with advancements in AI, IoT, and ubiquitous computing, which highlighted the importance of context in creating intelligent and adaptive systems.\n",
            "\n",
            "Would you like me to find more detailed or specific information about its origins and development?\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a machine learning technique where a pre-trained model is further trained on a specific dataset to adapt it to a particular task or domain. This process involves adjusting the model's parameters slightly to improve its performance on the target task, leveraging the knowledge the model has already acquired during its initial training on a large, general dataset.\n",
            "\n",
            "Fine-tuning has been a fundamental concept in deep learning for several years, especially with the rise of large pre-trained models like BERT, GPT, and others. It gained significant prominence around 2018-2019 when transformer-based models started dominating natural language processing (NLP) tasks. The ability to take a general language model and adapt it to specific tasks with relatively small amounts of task-specific data revolutionized NLP and other fields.\n",
            "\n",
            "Would you like me to provide a more detailed history or specific milestones related to the emergence of fine-tuning?\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are intelligent systems that utilize large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like text, and making decisions or taking actions based on the input they receive. These agents leverage the capabilities of LLMs like GPT-3, GPT-4, and similar models to interact with users, automate processes, and solve complex problems across different domains.\n",
            "\n",
            "The concept of LLM-based agents started gaining significant attention around 2020-2021, as large language models became more powerful and accessible. The release of OpenAI's GPT-3 in June 2020 marked a major milestone, showcasing the potential of LLMs to serve as foundational components for building intelligent agents. Since then, the development and deployment of LLM-based agents have rapidly expanded, becoming a prominent area of research and application in artificial intelligence.\n",
            "\n",
            "Would you like more detailed information on the history, specific applications, or recent advancements in LLM-based agents?\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
